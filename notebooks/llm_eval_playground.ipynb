{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM model hosting\n",
    "We use vllm to serve the 70B LLaMA-3.1 model for llm-as-a-judge evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6,7\"\n",
    "\n",
    "from mmassist.datasets.generate.llm_utils import LLMGenerator\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-70B-Instruct\"\n",
    "# model_id = \"neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8\" # for H100 or higher\n",
    "number_gpus = 4\n",
    "llm = LLMGenerator.build(model_id=model_id, number_gpus=number_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-Based Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, copy, random\n",
    "from mmassist.configs.arguments import DATA_ROOT_DIR\n",
    "\n",
    "file = f\"{DATA_ROOT_DIR}/processed_data/wtag/generated_dialogs/val.json\"\n",
    "generated_dialogs = json.load(open(file, \"r\"))\n",
    "print(generated_dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from mmassist.configs.arguments import DATA_ROOT_DIR\n",
    "\n",
    "I=1\n",
    "exp_dir = f\"../../ProAssist-Model-L4096-I{I}\"\n",
    "dataset_name = f\"ego4d-dialog_val_L0_I{I}\"\n",
    "runner = \"stream\"\n",
    "run_name = \"notalk0.5-maxlen_4k\"\n",
    "result_dir = os.path.join(exp_dir, \"eval\", dataset_name, runner, run_name, \"results\")\n",
    "\n",
    "print(len(os.listdir(result_dir)))\n",
    "# results = json.load(open(os.path.join(result_dir, \"all_results.json\")))\n",
    "# metrics = json.load(open(os.path.join(result_dir, \"metrics.json\")))\n",
    "# prediction = json.load(open(os.path.join(result_dir,\"results\", \"3.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "EVALUATION_SYS_PROMPT = \"\"\"You are an expert in evaluating the quality of user-assistant dialogues. Your task is to evaluate dialog responses generated by an assistant model that helps users with their tasks. You should evaluate the dialogs by comparing them to reference gold-standard dialogues from professional assistants.\n",
    "\n",
    "Requirement:\n",
    "1. Read dialogues carefully and compare them line by line. Keep you analysis concise and to the point.\n",
    "2. Evaluate the following aspects: \n",
    "- Correctness: does each generated instruction/feedback make sense (correct or relevant) or not, based on the context and the gold-standard reference?\n",
    "- Promptness: does the assistant provide guidance at the right time, or does it talk too early or too late?\n",
    "- Efficiency: does the assistant provide the necessary information in a concise and efficient manner, without too much repetition or redundancy information?\n",
    "- Overall: the overall helpfulness and quality of the assistant's responses.\n",
    "3. For each aspect, give a score from 1 to 5 based on the following criteria:\n",
    "- 1=very poor: most of utterances are incorrect, irrelevant, mistimed, inefficient etc\n",
    "- 2=poor: bad utterances that are incorrect, irrelevant, mistimed are more than good ones\n",
    "- 3=average: the number of good and bad utterances are roughly the same\n",
    "- 4=good: more good utterances than bad ones\n",
    "- 5=excellent: most of utterances are correct, relevant, timely, efficient etc\n",
    "\"\"\"\n",
    "\n",
    "DIALOG_EVALUATION_PROMPT_TEMPLATE = \"\"\"Gold-standard reference dialogue:\n",
    "{reference_dialog}\n",
    "\n",
    "Generated dialogue by the model:\n",
    "{generated_dialog}\n",
    "\n",
    "Format your answer as follows:\n",
    "<your step-by-step comparison and concise analysis>\n",
    "---\n",
    "{{\"correctness\": x, \"promptness\": y, \"efficiency\": z, \"overall\": w}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "score_fields = [\"correctness\", \"promptness\", \"efficiency\", \"overall\"]\n",
    "\n",
    "def parse_scores(text: str) -> dict | None:\n",
    "    scores = {}\n",
    "    if \"---\" in text:\n",
    "        text = text.split(\"---\")[1]\n",
    "    text = text.strip(\"\\n\")\n",
    "    try:\n",
    "        scores = json.loads(text)\n",
    "    except:\n",
    "        print(\"*\"*50)\n",
    "        print(text)\n",
    "        print(\"*\"*50)\n",
    "        return None\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_prompts = []\n",
    "for file in sorted(os.listdir(result_dir)):\n",
    "    with open(os.path.join(result_dir, file), \"r\") as f:\n",
    "        prediction = json.load(f)\n",
    "\n",
    "    gen_and_ref = prediction['predictions']\n",
    "    ref_dialog = \"\"\n",
    "    for turn in prediction['predictions']:\n",
    "        time = turn['timestamp_in_stream']\n",
    "        for t in turn[\"text_inputs\"]:\n",
    "            if t[0] == \"user\":\n",
    "                ref_dialog += f\"[{time}s] User: {t[1]}\\n\"\n",
    "        if turn[\"ref\"]:\n",
    "            ref_dialog += f\"[{time}s] Assistant: {turn['ref']}\\n\"\n",
    "\n",
    "    gen_dialog = \"\"\n",
    "    for turn in prediction['predictions']:\n",
    "        time = turn['timestamp_in_stream']\n",
    "        for t in turn[\"text_inputs\"]:\n",
    "            if t[0] == \"user\":\n",
    "                gen_dialog += f\"[{time}s] User: {t[1]}\\n\"\n",
    "        if turn[\"gen\"]:\n",
    "            gen_dialog += f\"[{time}s] Assistant: {turn['gen']}\\n\"\n",
    "    \n",
    "    prompt = DIALOG_EVALUATION_PROMPT_TEMPLATE.format(\n",
    "        reference_dialog=ref_dialog, generated_dialog=gen_dialog\n",
    "    )\n",
    "    inputs = [(\"system\", EVALUATION_SYS_PROMPT), (\"user\", prompt)]\n",
    "    \n",
    "    all_predictions.append({\n",
    "        \"file\": file,\n",
    "        \"ref\": ref_dialog,\n",
    "        \"gen\": gen_dialog,\n",
    "    })\n",
    "    all_prompts.append(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [04:54<00:00, 24.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_repeat = 3\n",
    "outputs = []\n",
    "batch_size = 8\n",
    "for i in tqdm(range(0, len(all_prompts), batch_size)):\n",
    "    batch_prompts = all_prompts[i:i+batch_size]\n",
    "    batch_outputs = llm.batch_generate(batch_prompts, n=num_repeat)\n",
    "    outputs.extend(batch_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5s] User: I want to prepare a multi-course meal with grilled fish, meat, and rice.\n",
      "[1.5s] Assistant: Great goal! To start, let's gather all the ingredients we need. Please collect the fish, meat, rice, and any seasonings or spices you'd like to use.\n",
      "[139.5s] Assistant: Now that we have all the ingredients, let's start preparing the rice. Please wash the rice thoroughly to remove any impurities.\n",
      "[157.0s] Assistant: Next, add water to the rice. Make sure the water level is at the recommended ratio. Then, put the rice in the rice cooker and turn it on.\n",
      "[188.5s] Assistant: While the rice is cooking, let's prepare the grill. Please preheat it to the right temperature for grilling the fish and meat.\n",
      "[203.5s] Assistant: Now, let's move on to preparing the fish. Please unwrap the fish and wash it to remove any impurities.\n",
      "[228.5s] Assistant: Next, add some oil to the fish to prevent it from sticking to the grill. Then, add your desired seasonings or spices to the fish. You can use salt, pepper, or any other herbs you like.\n",
      "[285.5s] Assistant: Now, let's prepare the meat. Please wash the meat to remove any impurities.\n",
      "[300.0s] Assistant: Next, add some oil to the meat to prevent it from sticking to the grill. Then, add your desired seasonings or spices to the meat. You can use salt, pepper, or any other herbs you like.\n",
      "[309.0s] Assistant: Now that the meat is prepared, let's make sure the grill is at the right temperature. Please check the grill temperature and adjust it if needed.\n",
      "[339.0s] Assistant: Great job so far! Now, let's store the unused meat in the refrigerator to keep it fresh. Please put the meat away and make sure it's securely stored.\n",
      "[364.5s] Assistant: Now, let's focus on grilling the fish. Please place the fish on the grill and cook it for a few minutes on each side.\n",
      "[391.5s] Assistant: While the fish is cooking, let's prepare the meat for grilling. Please place the meat on the grill and cook it for a few minutes on each side.\n",
      "[405.0s] Assistant: Now, let's flip the fish to ensure even cooking. Please flip the fish over and cook for a few more minutes.\n",
      "[419.5s] Assistant: Great job! Now, let's flip the meat to ensure even cooking. Please flip the meat over and cook for a few more minutes.\n",
      "[429.0s] Assistant: Now, let's check on the fish. Please check the fish for doneness and adjust the grill temperature if needed.\n",
      "[439.5s] Assistant: Now, let's check on the fish again. Please check the fish for doneness and adjust the grill temperature if needed.\n",
      "[450.0s] Assistant: Great job! Now, let's flip the fish one more time to ensure it's cooked evenly. Please flip the fish over and cook for a few more minutes.\n",
      "[482.0s] Assistant: Now, let's check on the fish again. Please check the fish for doneness and adjust the grill temperature if needed.\n",
      "[494.5s] Assistant: Now, let's move on to preparing the vegetable. Please collect the vegetable from the refrigerator.\n",
      "[499.5s] Assistant: Next, please collect a plate to hold the vegetable.\n",
      "[506.0s] Assistant: Now, let's serve the vegetable. Please place the vegetable on the plate.\n",
      "[509.0s] Assistant: Great job! Now, let's serve the meat. Please place the meat on the plate.\n",
      "[518.5s] Assistant: Now, let's check on the fish one last time. Please check the fish for doneness and adjust the grill temperature if needed.\n",
      "[524.5s] Assistant: Now, let's serve the rice. Please remove the cooked rice from the rice cooker and place it on the plate.\n",
      "[529.0s] Assistant: Great job! Now, let's turn off the stove to conserve energy. Please turn off the stove.\n",
      "[531.0s] Assistant: Now, let's serve the vegetable soup. Please ladle the vegetable soup into a bowl.\n",
      "[548.5s] Assistant: Now, let's serve the meat soup. Please ladle the meat soup into a bowl.\n",
      "[553.5s] Assistant: Great job! Now, let's serve the fish. Please place the fish on the plate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_predictions[0]['gen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'correctness': '3.67', 'promptness': '3.00', 'efficiency': '2.33', 'overall': '3.00'}\n",
      "1 {'correctness': '2.33', 'promptness': '2.33', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "2 {'correctness': '3.67', 'promptness': '3.33', 'efficiency': '2.33', 'overall': '3.33'}\n",
      "3 {'correctness': '3.17', 'promptness': '3.00', 'efficiency': '2.17', 'overall': '2.67'}\n",
      "4 {'correctness': '1.00', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "5 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "6 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "7 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "8 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "9 {'correctness': '2.00', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "10 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "11 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "12 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "13 {'correctness': '3.67', 'promptness': '3.00', 'efficiency': '2.00', 'overall': '2.83'}\n",
      "14 {'correctness': '1.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "15 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "16 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "17 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "18 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "19 {'correctness': '3.33', 'promptness': '3.33', 'efficiency': '2.67', 'overall': '3.17'}\n",
      "20 {'correctness': '3.33', 'promptness': '2.67', 'efficiency': '2.67', 'overall': '2.83'}\n",
      "21 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "22 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "23 {'correctness': '1.33', 'promptness': '1.67', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "24 {'correctness': '1.67', 'promptness': '2.33', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "25 {'correctness': '2.00', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "26 {'correctness': '2.67', 'promptness': '3.00', 'efficiency': '2.67', 'overall': '2.67'}\n",
      "27 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "28 {'correctness': '1.33', 'promptness': '1.67', 'efficiency': '1.33', 'overall': '1.33'}\n",
      "29 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "30 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "31 {'correctness': '1.33', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "32 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "33 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.00', 'overall': '1.67'}\n",
      "34 {'correctness': '1.33', 'promptness': '1.67', 'efficiency': '1.33', 'overall': '1.33'}\n",
      "35 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "36 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "37 {'correctness': '1.00', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "38 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '1.67'}\n",
      "39 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "40 {'correctness': '1.00', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "41 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "42 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '1.67'}\n",
      "43 {'correctness': '1.33', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "44 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.00', 'overall': '1.67'}\n",
      "45 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '1.67'}\n",
      "46 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '1.67'}\n",
      "47 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "48 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "49 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "50 {'correctness': '1.00', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "51 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "52 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.33', 'overall': '2.17'}\n",
      "53 {'correctness': '1.67', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "54 {'correctness': '2.00', 'promptness': '2.67', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "55 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "56 {'correctness': '2.67', 'promptness': '2.67', 'efficiency': '3.00', 'overall': '2.67'}\n",
      "57 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "58 {'correctness': '2.33', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "59 {'correctness': '2.67', 'promptness': '2.33', 'efficiency': '2.33', 'overall': '2.50'}\n",
      "60 {'correctness': '1.33', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "61 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '1.67'}\n",
      "62 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "63 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "64 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "65 {'correctness': '2.67', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "66 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '1.67'}\n",
      "67 {'correctness': '1.33', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "68 {'correctness': '2.00', 'promptness': '3.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "69 {'correctness': '2.33', 'promptness': '3.67', 'efficiency': '2.67', 'overall': '2.67'}\n",
      "70 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "71 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "72 {'correctness': '2.83', 'promptness': '2.33', 'efficiency': '2.33', 'overall': '2.50'}\n",
      "73 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "74 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.00', 'overall': '1.67'}\n",
      "75 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.00', 'overall': '1.67'}\n",
      "76 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "77 {'correctness': '3.33', 'promptness': '3.33', 'efficiency': '2.33', 'overall': '3.17'}\n",
      "78 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "79 {'correctness': '2.67', 'promptness': '3.00', 'efficiency': '2.33', 'overall': '2.50'}\n",
      "80 {'correctness': '1.33', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "81 {'correctness': '1.00', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "82 {'correctness': '2.33', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "83 {'correctness': '3.00', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '2.50'}\n",
      "84 {'correctness': '2.50', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.17'}\n",
      "85 {'correctness': '2.33', 'promptness': '3.00', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "86 {'correctness': '1.00', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "87 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "88 {'correctness': '2.33', 'promptness': '2.33', 'efficiency': '1.33', 'overall': '2.33'}\n",
      "89 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "90 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "91 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "92 {'correctness': '1.67', 'promptness': '2.33', 'efficiency': '1.33', 'overall': '1.67'}\n",
      "93 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "94 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "95 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '1.67'}\n",
      "correctness: 1.99\n",
      "promptness: 2.09\n",
      "efficiency: 1.53\n",
      "overall: 1.93\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_scores(text: str) -> dict | None:\n",
    "    scores = {}\n",
    "    if \"---\" in text:\n",
    "        text = text.split(\"---\")[1]\n",
    "    try:\n",
    "        text = re.findall(r\"\\{.*?\\}\", text)[0]\n",
    "        scores = json.loads(text)\n",
    "    except:\n",
    "        # print(\"*\"*50)\n",
    "        # print(text)\n",
    "        # print(\"*\"*50)\n",
    "        return None\n",
    "    return scores\n",
    "\n",
    "for idx, (pred, out) in enumerate(zip(all_predictions, outputs)):\n",
    "    # print(pred[\"file\"])\n",
    "    # print(out[0])\n",
    "\n",
    "    all_scores = {k:[] for k in score_fields}\n",
    "    for i in range(num_repeat):\n",
    "        parsed_dict = parse_scores(out[i])\n",
    "        if parsed_dict:\n",
    "            for k, v in parsed_dict.items():\n",
    "                all_scores[k].append(v)\n",
    "    \n",
    "    \n",
    "    pred[\"all_scores\"] = all_scores\n",
    "    pred[\"llm_outputs\"] = out\n",
    "    mean_scores = {}\n",
    "    for k, v in all_scores.items():\n",
    "        if v:\n",
    "            mean_scores[k] = sum(v) / len(v)\n",
    "        else:\n",
    "            mean_scores[k] = None\n",
    "    print(idx, {k: f\"{v:.2f}\" if v else None for k, v in mean_scores.items()})\n",
    "    pred[\"scores\"] = mean_scores\n",
    "    # print(\"\\n\\n\\n\")\n",
    "\n",
    "# compute the mean of each score\n",
    "for m in score_fields:\n",
    "    scores = [p[\"scores\"][m] for p in all_predictions if p[\"scores\"][m]]\n",
    "    mean_score = sum(scores) / len(scores)\n",
    "    print(f\"{m}: {mean_score:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "save_file = \"llm_eval_try4.json\"\n",
    "with open(save_file, \"w\") as f:\n",
    "    json.dump(all_predictions, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness: 1.95\n",
    "promptness: 2.10\n",
    "efficiency: 1.52\n",
    "overall: 1.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness: 2.13\n",
    "promptness: 2.32\n",
    "efficiency: 1.79\n",
    "overall: 2.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'correctness': '2.17', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '2.17'}\n",
      "1 {'correctness': '2.00', 'promptness': '1.67', 'efficiency': '1.00', 'overall': '1.67'}\n",
      "2 {'correctness': '3.00', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.67'}\n",
      "3 {'correctness': '2.33', 'promptness': '2.67', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "4 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "5 {'correctness': '3.20', 'promptness': '3.50', 'efficiency': '2.50', 'overall': '3.25'}\n",
      "6 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "7 {'correctness': '2.33', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "8 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "9 {'correctness': '1.67', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "10 {'correctness': '1.93', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "11 {'correctness': '1.00', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "12 {'correctness': '1.00', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "13 {'correctness': '2.33', 'promptness': '1.67', 'efficiency': '2.67', 'overall': '2.00'}\n",
      "14 {'correctness': '2.50', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "15 {'correctness': '2.50', 'promptness': '3.00', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "16 {'correctness': '1.33', 'promptness': '1.67', 'efficiency': '1.33', 'overall': '1.33'}\n",
      "17 {'correctness': '1.33', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "18 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "19 {'correctness': '3.00', 'promptness': '3.00', 'efficiency': '2.33', 'overall': '3.00'}\n",
      "20 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.33', 'overall': '1.67'}\n",
      "21 {'correctness': '2.50', 'promptness': '2.60', 'efficiency': '2.17', 'overall': '2.17'}\n",
      "22 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '1.83'}\n",
      "23 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "24 {'correctness': '1.50', 'promptness': '1.67', 'efficiency': '1.00', 'overall': '1.67'}\n",
      "25 {'correctness': '3.00', 'promptness': '3.33', 'efficiency': '2.33', 'overall': '2.83'}\n",
      "26 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "27 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "28 {'correctness': '2.83', 'promptness': '2.50', 'efficiency': '2.50', 'overall': '2.67'}\n",
      "29 {'correctness': '1.70', 'promptness': '1.90', 'efficiency': '1.63', 'overall': '1.73'}\n",
      "30 {'correctness': '1.33', 'promptness': '1.67', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "31 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "32 {'correctness': '1.00', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "33 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "34 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "35 {'correctness': '2.33', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "36 {'correctness': '2.33', 'promptness': '3.00', 'efficiency': '2.33', 'overall': '2.33'}\n",
      "37 {'correctness': '2.33', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "38 {'correctness': '2.67', 'promptness': '3.00', 'efficiency': '2.33', 'overall': '2.50'}\n",
      "39 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "40 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "41 {'correctness': '1.33', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.33'}\n",
      "42 {'correctness': '2.33', 'promptness': '2.67', 'efficiency': '1.33', 'overall': '2.33'}\n",
      "43 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "44 {'correctness': '2.00', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "45 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.50', 'overall': '2.00'}\n",
      "46 {'correctness': '1.33', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '1.33'}\n",
      "47 {'correctness': '2.33', 'promptness': '2.67', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "48 {'correctness': '3.17', 'promptness': '4.00', 'efficiency': '2.83', 'overall': '3.00'}\n",
      "49 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "50 {'correctness': '2.33', 'promptness': '2.33', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "51 {'correctness': '1.33', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "52 {'correctness': '1.67', 'promptness': '1.67', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "53 {'correctness': '2.33', 'promptness': '3.00', 'efficiency': '2.33', 'overall': '2.33'}\n",
      "54 {'correctness': '2.67', 'promptness': '2.83', 'efficiency': '2.83', 'overall': '2.50'}\n",
      "55 {'correctness': '3.40', 'promptness': '3.67', 'efficiency': '3.43', 'overall': '3.40'}\n",
      "56 {'correctness': '2.33', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "57 {'correctness': '2.83', 'promptness': '3.00', 'efficiency': '2.67', 'overall': '2.60'}\n",
      "58 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "59 {'correctness': '2.33', 'promptness': '3.33', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "60 {'correctness': '2.60', 'promptness': '3.07', 'efficiency': '3.07', 'overall': '2.83'}\n",
      "61 {'correctness': '2.33', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "62 {'correctness': '2.33', 'promptness': '2.33', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "63 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "64 {'correctness': '3.00', 'promptness': '3.00', 'efficiency': '2.67', 'overall': '2.67'}\n",
      "65 {'correctness': '1.33', 'promptness': '1.67', 'efficiency': '1.67', 'overall': '1.33'}\n",
      "66 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "67 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "68 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.67', 'overall': '1.67'}\n",
      "69 {'correctness': '1.00', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "70 {'correctness': '2.50', 'promptness': '2.50', 'efficiency': '2.50', 'overall': '2.50'}\n",
      "71 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "72 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '1.67'}\n",
      "73 {'correctness': '2.17', 'promptness': '3.00', 'efficiency': '1.67', 'overall': '2.17'}\n",
      "74 {'correctness': '3.00', 'promptness': '3.67', 'efficiency': '3.00', 'overall': '3.00'}\n",
      "75 {'correctness': '3.40', 'promptness': '4.07', 'efficiency': '3.07', 'overall': '3.23'}\n",
      "76 {'correctness': '1.33', 'promptness': '1.00', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "77 {'correctness': '1.00', 'promptness': '1.33', 'efficiency': '1.00', 'overall': '1.00'}\n",
      "78 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '2.00'}\n",
      "79 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "80 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "81 {'correctness': '2.33', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.50'}\n",
      "82 {'correctness': '3.40', 'promptness': '4.00', 'efficiency': '3.67', 'overall': '3.67'}\n",
      "83 {'correctness': '2.33', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.33'}\n",
      "84 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '1.33', 'overall': '1.67'}\n",
      "85 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.67', 'overall': '2.00'}\n",
      "86 {'correctness': '2.00', 'promptness': '2.33', 'efficiency': '1.33', 'overall': '2.00'}\n",
      "87 {'correctness': '2.33', 'promptness': '3.67', 'efficiency': '2.33', 'overall': '2.33'}\n",
      "88 {'correctness': '1.67', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '1.67'}\n",
      "89 {'correctness': '2.50', 'promptness': '2.33', 'efficiency': '1.67', 'overall': '2.33'}\n",
      "90 {'correctness': '2.00', 'promptness': '2.00', 'efficiency': '2.00', 'overall': '2.00'}\n",
      "91 {'correctness': '1.50', 'promptness': '2.00', 'efficiency': '1.00', 'overall': '1.50'}\n",
      "92 {'correctness': '2.33', 'promptness': '3.33', 'efficiency': '2.67', 'overall': '2.33'}\n",
      "93 {'correctness': '3.67', 'promptness': '3.00', 'efficiency': '2.67', 'overall': '3.17'}\n",
      "94 {'correctness': '2.67', 'promptness': '2.67', 'efficiency': '2.33', 'overall': '2.50'}\n",
      "95 {'correctness': '3.00', 'promptness': '2.67', 'efficiency': '2.00', 'overall': '2.67'}\n",
      "correctness: 2.13\n",
      "promptness: 2.32\n",
      "efficiency: 1.79\n",
      "overall: 2.06\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_scores(text: str) -> dict | None:\n",
    "    scores = {}\n",
    "    if \"---\" in text:\n",
    "        text = text.split(\"---\")[1]\n",
    "    try:\n",
    "        text = re.findall(r\"\\{.*?\\}\", text)[0]\n",
    "        scores = json.loads(text)\n",
    "    except:\n",
    "        # print(\"*\"*50)\n",
    "        # print(text)\n",
    "        # print(\"*\"*50)\n",
    "        return None\n",
    "    return scores\n",
    "\n",
    "for idx, (pred, out) in enumerate(zip(all_predictions, outputs)):\n",
    "    # print(pred[\"file\"])\n",
    "    # print(out[0])\n",
    "\n",
    "    all_scores = {k:[] for k in score_fields}\n",
    "    for i in range(num_repeat):\n",
    "        parsed_dict = parse_scores(out[i])\n",
    "        if parsed_dict:\n",
    "            for k, v in parsed_dict.items():\n",
    "                all_scores[k].append(v)\n",
    "    \n",
    "    \n",
    "    pred[\"all_scores\"] = all_scores\n",
    "    pred[\"llm_outputs\"] = out\n",
    "    mean_scores = {}\n",
    "    for k, v in all_scores.items():\n",
    "        if v:\n",
    "            mean_scores[k] = sum(v) / len(v)\n",
    "        else:\n",
    "            mean_scores[k] = None\n",
    "    print(idx, {k: f\"{v:.2f}\" if v else None for k, v in mean_scores.items()})\n",
    "    pred[\"scores\"] = mean_scores\n",
    "    # print(\"\\n\\n\\n\")\n",
    "\n",
    "# compute the mean of each score\n",
    "for m in score_fields:\n",
    "    scores = [p[\"scores\"][m] for p in all_predictions if p[\"scores\"][m]]\n",
    "    mean_score = sum(scores) / len(scores)\n",
    "    print(f\"{m}: {mean_score:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "save_file = \"llm_eval.json\"\n",
    "with open(save_file, \"w\") as f:\n",
    "    json.dump(all_predictions, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = DIALOG_EVALUATION_PROMPT_TEMPLATE.format(\n",
    "    reference_dialog=ref_dialog, generated_dialog=gen_dialog\n",
    ")\n",
    "inputs = [(\"system\", EVALUATION_SYS_PROMPT), (\"user\", prompt)]\n",
    "outputs = llm.generate(inputs, n=5)\n",
    "# print(outputs[0])\n",
    "\n",
    "all_scores = {k:[] for k in score_fields}\n",
    "for i in range(5):\n",
    "    scores = parse_scores(outputs[i])\n",
    "    if scores:\n",
    "        for k, v in scores.items():\n",
    "            all_scores[k].append(v)\n",
    "print(all_scores)\n",
    "for k, v in all_scores.items():\n",
    "    avg = sum(v) / len(v)\n",
    "    print(f\"{k}: {avg:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
