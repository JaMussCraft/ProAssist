{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/miniconda3/envs/mm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the base LLM from meta-llama/Meta-Llama-3.1-8B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging adapter 0 from /mnt/bn/ic-vlm/personal/zhangyic/open/ProAssist-Model-L4096-I10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from mmassist.model import build_from_checkpoint\n",
    "from mmassist.configs.arguments import EvalArguments\n",
    "from mmassist.eval.eval_utils import parse_inference_setups\n",
    "\n",
    "ckpt = \"/mnt/bn/ic-vlm/personal/zhangyic/open/ProAssist-Model-L4096-I10\"\n",
    "inference_setups = \"wtag/dialog-klg_val_L0_I1|stream|4k|0.5|summarize_and_drop\"\n",
    "eval_args = EvalArguments(model_path=ckpt, inference_setups=inference_setups)\n",
    "args_dict = eval_args.to_dict()\n",
    "\n",
    "model, tokenizer = build_from_checkpoint(ckpt)\n",
    "model.config.exceed_context_handling = \"summarize_and_drop\"\n",
    "\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.exceed_context_handling = \"summarize_and_drop\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sthsthv2/narration_val_L4096_I10,ego4d/dialog-klg-sum_val_L4096_I10,holoassist/dialog-klg-sum_val_L4096_I10,ego4d/narration_val_L4096_I10,ego4d/summary_val_L4096_I10\n",
      "Evaluation datasets:\n",
      "* wtag/dialog-klg_val | num samples: 21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmassist.data import build_train_dataset, build_eval_datasets\n",
    "from mmassist.configs.arguments import DATA_ROOT_DIR\n",
    "DATA_ROOT_DIR = \"/mnt/bn/ic-vlm/personal/zhangyic/open/ProAssist-Dataset\"\n",
    "\n",
    "eval_on_training_data = False\n",
    "\n",
    "config = model.config\n",
    "config.data_root_dir = f\"{DATA_ROOT_DIR}/processed_data\"\n",
    "config.training_args[\"data_root_dir\"] = f\"{DATA_ROOT_DIR}/processed_data\"\n",
    "\n",
    "\n",
    "train_datasets = config.training_args[\"train_datasets\"].replace(\"dialog_klg_sum\", \"dialog-klg-sum\")\n",
    "eval_datasets = config.training_args[\"eval_datasets\"].replace(\"dialog_klg_sum\", \"dialog-klg-sum\")\n",
    "# eval_datasets = \"sthsthv2/narration_val_L4096_I10,\" + eval_datasets\n",
    "\n",
    "# eval_datasets = \"ego4d/dialog_val_L0_I10\"\n",
    "eval_datasets = inference_setups.split(\"|\")[0]\n",
    "print(config.training_args[\"eval_datasets\"])\n",
    "\n",
    "config.training_args[\"train_datasets\"] = train_datasets\n",
    "config.training_args[\"eval_datasets\"] = eval_datasets\n",
    "\n",
    "# the original model arguments\n",
    "all_args_dict = config.to_dict()\n",
    "all_args_dict.update(config.training_args)\n",
    "\n",
    "if not eval_on_training_data:\n",
    "    dataset_dict = build_eval_datasets(**all_args_dict, print_info=True, keep_images=True)\n",
    "    datasets = list(dataset_dict.values())\n",
    "else:\n",
    "    datasets = build_train_dataset(**all_args_dict, print_info=True, keep_images=True)\n",
    "    datasets = datasets.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Streaming Inference Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmassist.eval.runners.stream_inference import StreamInferenceRunner, FrameOutput\n",
    "\n",
    "dataset = datasets[0]\n",
    "not_talk_threshold = 0.3\n",
    "runner = StreamInferenceRunner.build(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    fps=2,\n",
    "    eval_max_seq_len=4096,\n",
    "    not_talk_threshold=not_talk_threshold,\n",
    "    eval_name=\"demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run streaming inference on a single video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "!!! Set vision encoder in the model, only recommended for on in-the-wild inference. Please dont call this for efficient training & evaluation. Instead, do visual feature pre-extraction.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5s] SYSTEM: You are a proactive assistant. Predict the user's needs and provide assistance before being requested.\n",
      "[0.5s] REF : \n",
      "[0.5s] GEN : \n",
      "Context Length: 34\n",
      "[7.0s] USER: I want to make pour-over coffee.\n",
      "[7.0s] SYSTEM: Task knowledge: Pour-over Coffee\n",
      "\n",
      "Ingredients\n",
      "12 oz water\n",
      "25 grams whole coffee beans\n",
      "\n",
      "Tools and Utensils\n",
      "2-cup liquid measuring cup electric kettle\n",
      "kitchen scale\n",
      "coffee grinder\n",
      "filter cone dripper (stainless steel)\n",
      "paper basket filter (standard 8-12 cup size) 12-ounce coffee mug\n",
      "thermometer\n",
      "timer (optional)\n",
      "\n",
      "Steps\n",
      "1. Measure 12 ounces of cold water and transfer to a kettle.\n",
      "2. While the water is boiling, assemble the filter cone. Place the dripper on top of a coffee mug.\n",
      "3. Prepare the filter insert by folding the paper filter in half to create a semi-circle, and in half again\n",
      "to create a quarter-circle. Place the paper filter in the dripper and spread open to create a cone.\n",
      "4. Weigh the coffee beans and grind until the coffee grounds are the consistency of coarse sand,\n",
      "about 20 seconds. Transfer the grounds to the filter cone.\n",
      "5. Once the water has boiled, check the temperature. The water should be between 195-205\n",
      "degrees Fahrenheit or between 91-96 degrees Celsius. If the water is too hot, let it cool briefly.\n",
      "6. Pour a small amount of water in the filter to wet the grounds. Wait about 30 seconds for coffee\n",
      "to bloom. You will see small bubbles or foam on the coffee grounds during this step.\n",
      "7. Slowly pour the rest of the water over the grounds in a circular motion. Do not overfill beyond\n",
      "the top of the paper filter.\n",
      "8. Let the coffee drain completely into the mug before removing the dripper. Discard the paper\n",
      "filter and coffee grounds.\n",
      "[7.0s] REF : Great! To start, let's boil some water. You can use the water that's in that jug.\n",
      "[7.0s] GEN : Great choice! Pour-over coffee is a classic. To start, you'll need to boil some water. Let's get that going.\n",
      "Context Length: 554\n",
      "[21.5s] REF : Now, please measure 12 ounces of water into the measuring cup. Don't worry if there's already some water in it, it should be fine.\n",
      "[21.5s] GEN : \n",
      "Context Length: 844\n",
      "[25.5s] USER: The jug like this? Oh\n",
      "[25.5s] REF : Yes, that's the one. Just add enough to make 12 ounces.\n",
      "[25.5s] GEN : Yes, that's correct. Now, you'll need to measure out twelve ounces of water.\n",
      "Context Length: 958\n",
      "[43.0s] USER: Oh, okay. It already has some water in it, should I first...?\n",
      "[43.0s] REF : No need to worry about that, just add enough to make 12 ounces.\n",
      "[43.0s] GEN : No, that's fine. Just use the measuring cup to get the right amount.\n",
      "Context Length: 1351\n",
      "[57.0s] USER: Twelve ounces.\n",
      "[57.0s] REF : Great! Now, let's move on to assembling the filter cone.\n",
      "[57.0s] GEN : That's right. Now, let's move on to assembling the filter cone.\n",
      "Context Length: 1660\n",
      "[103.5s] REF : Okay, now it's time to prepare the filter cone. Can you find the metal filter cone?\n",
      "[103.5s] GEN : \n",
      "Context Length: 2590\n",
      "[108.0s] USER: Prepare filter cone?\n",
      "[108.0s] REF : Yes, it's the metal thing. Not that one, the other one.\n",
      "[108.0s] GEN : Yes, that's right. You'll need to set up the filter cone using the dripper and coffee.\n",
      "Context Length: 2715\n",
      "[111.0s] USER: Is this the filter cone?\n",
      "[111.0s] REF : No, not that one. The metal one is the filter cone.\n",
      "[111.0s] GEN : Yes, that's the one. Now, you'll need to place the dripper on top of a coffee mug.\n",
      "Context Length: 2814\n",
      "[113.0s] REF : Now, put the filter cone on the mug.\n",
      "[113.0s] GEN : \n",
      "Context Length: 2854\n",
      "[115.5s] USER: Oh, this one? Okay\n",
      "[115.5s] REF : Yes, that's the one. Now, put a paper filter in the cone.\n",
      "[115.5s] GEN : That's right. Now, you'll need to prepare the filter.\n",
      "Context Length: 2933\n",
      "[126.5s] USER: And I put paper?\n",
      "[126.5s] REF : Yes, that's right. Before you put the paper filter in the cone, you need to fold it in half.\n",
      "[126.5s] GEN : Yes, that's right. You'll need to put a paper filter in the cone.\n",
      "Context Length: 3185\n",
      "[137.0s] REF : Then, fold it in half again, into quarters.\n",
      "[137.0s] GEN : \n",
      "Context Length: 3395\n",
      "[140.5s] USER: Fold it in half?\n",
      "[140.5s] REF : Yes, just like that.\n",
      "[140.5s] GEN : Yes, that's right. And then fold it in half again.\n",
      "Context Length: 3493\n",
      "[146.0s] REF : Now, put the folded filter into the cone.\n",
      "[146.0s] GEN : \n",
      "Context Length: 3603\n",
      "[154.0s] USER: Oh, okay. Okay.\n",
      "[154.0s] REF : Great! Now, you can put the filter into the filter cone.\n",
      "[154.0s] GEN : Now, you'll need to put the folded filter in the cone.\n",
      "Context Length: 3792\n",
      "[159.5s] REF : \n",
      "[159.5s] GEN : Now, let's move on to grinding the coffee beans.\n",
      "Context Length: 3918\n",
      "IPS envoked - Generated summary: The time elapsed since the start of the task is 158.4 seconds. The user wants to make pour-over coffee, has boiled water, measured out 12 ounces, and is currently in the process of assembling the filter cone, having placed the dripper on top of a coffee mug and prepared the paper filter by folding it in half twice, with the next step being to grind the coffee beans.\n",
      "[162.5s] REF : And then you can spread it open.\n",
      "[162.5s] GEN : \n",
      "Context Length: 456\n",
      "[168.0s] REF : Great! Now, let's move on to grinding the coffee beans. You'll need to measure out 25 grams of coffee beans.\n",
      "[168.0s] GEN : \n",
      "Context Length: 566\n",
      "[194.0s] USER: I use a spoon to, uh, to transport it?\n",
      "[194.0s] REF : Yes, that's right. You can use that scale to measure the beans.\n",
      "[194.0s] GEN : Yeah, that's right! Use the spoon to transport the coffee beans.\n",
      "Context Length: 1122\n",
      "[202.5s] USER: Oh, twenty-five grams, okay\n",
      "[202.5s] REF : Yes, that's right.\n",
      "[202.5s] GEN : That's right! You need 25 grams of coffee beans.\n",
      "Context Length: 1321\n",
      "[206.0s] USER: Uh, I use this one to measure it?\n",
      "[206.0s] REF : Yes, that's the one.\n",
      "[206.0s] GEN : Yeah, use the scale to measure out 25 grams of coffee beans.\n",
      "Context Length: 1425\n",
      "[223.5s] USER: Twenty-five, right?\n",
      "[223.5s] REF : Yes, that's right.\n",
      "[223.5s] GEN : That's right! You've got 25 grams of coffee beans.\n",
      "Context Length: 1803\n",
      "[271.5s] USER: Then pour in water?\n",
      "[271.5s] REF : Not yet! First, you need to grind the coffee beans using the grinder.\n",
      "[271.5s] GEN : Yeah, that's right! Once the water is boiled, you'll pour it over the coffee beans.\n",
      "Context Length: 2798\n",
      "[277.0s] USER: So I should put this coffee beans in the filter, right?\n",
      "[277.0s] REF : No, not yet. First, you need to grind the beans. Can you find the grinder?\n",
      "[277.0s] GEN : Yeah, that's right! You'll put the coffee beans in the filter.\n",
      "Context Length: 2946\n",
      "[281.0s] REF : It's that machine over there.\n",
      "[281.0s] GEN : \n",
      "Context Length: 3026\n",
      "[284.5s] USER: Grinder?\n",
      "[284.5s] REF : Yes, that's the one.\n",
      "[284.5s] GEN : Yeah, use the grinder to grind the coffee beans.\n",
      "Context Length: 3119\n",
      "[287.0s] USER: Oh, this one, okay\n",
      "[287.0s] REF : Great! Now, take the lid off and put the beans in.\n",
      "[287.0s] GEN : That's right! Use the grinder to grind the coffee beans.\n",
      "Context Length: 3197\n",
      "[291.5s] REF : Yes, just like that.\n",
      "[291.5s] GEN : \n",
      "Context Length: 3287\n",
      "[299.0s] USER: Yeah, sure\n",
      "[299.0s] REF : Now, put the lid back on and turn on the grinder. The button is on the lid.\n",
      "[299.0s] GEN : Great! Now, let's grind the coffee beans.\n",
      "Context Length: 3460\n",
      "[307.5s] REF : Great! Now, the coffee should be ground to a consistency like coarse sand.\n",
      "[307.5s] GEN : \n",
      "Context Length: 3630\n",
      "[317.0s] REF : Can you see the large black part on the grinder? That's the button to turn it on.\n",
      "[317.0s] GEN : \n",
      "Context Length: 3820\n",
      "[320.0s] USER: Oh, this one, oh, okay\n",
      "[320.0s] REF : Great! Now, pour the ground coffee into the filter cone.\n",
      "[320.0s] GEN : That's right! Use the grinder to grind the coffee beans.\n",
      "Context Length: 3910\n",
      "IPS envoked - Generated summary: The time elapsed since the start of the task is 300.4 seconds. The user wants to make pour-over coffee, and so far, they have boiled water, measured out 12 ounces of water, assembled the filter cone, placed the dripper on top of a coffee mug, prepared the paper filter by folding it in half twice, and measured out 25 grams of coffee beans, with the current step being to grind the coffee beans using the grinder.\n",
      "[347.0s] USER: Okay\n",
      "[347.0s] REF : Great! Now, let's move on to checking the water temperature. We need to make sure the water is between 195 and 205 degrees Fahrenheit.\n",
      "[347.0s] GEN : \n",
      "Context Length: 944\n",
      "[350.0s] USER: So you mean I pour this one into the filter cone?\n",
      "[350.0s] REF : Yes, that's right. Now, let's pour a little water over the coffee grounds to wet them.\n",
      "[350.0s] GEN : \n",
      "Context Length: 1021\n",
      "[352.0s] REF : \n",
      "[352.0s] GEN : Yep, that's correct!\n",
      "Context Length: 1071\n",
      "[380.5s] REF : Great! Now, the coffee should start to bloom. You'll see bubbles forming on the surface.\n",
      "[380.5s] GEN : \n",
      "Context Length: 1641\n",
      "[395.0s] USER: Then I pour the hot water?\n",
      "[395.0s] REF : Yes, that's right. But first, let me check the temperature. Okay, it looks good.\n",
      "[395.0s] GEN : \n",
      "Context Length: 1943\n",
      "[396.5s] REF : \n",
      "[396.5s] GEN : Not yet! First, let's check the water temperature.\n",
      "Context Length: 1989\n",
      "[424.0s] USER: Is it good?\n",
      "[424.0s] REF : Yes, it's fine. Now, pour a little water over the coffee grounds to wet them.\n",
      "[424.0s] GEN : \n",
      "Context Length: 2548\n",
      "[439.0s] REF : Just pour a little at first, enough to cover all the grounds.\n",
      "[439.0s] GEN : \n",
      "Context Length: 2848\n",
      "[461.5s] REF : Great! Now, the coffee should start to bloom. You'll see bubbles forming on the surface.\n",
      "[461.5s] GEN : \n",
      "Context Length: 3298\n",
      "[464.5s] USER: Yes\n",
      "[464.5s] REF : Great! Now, you can pour the rest of the water over the coffee.\n",
      "[464.5s] GEN : \n",
      "Context Length: 3364\n",
      "[466.0s] REF : \n",
      "[466.0s] GEN : Great! Now, let's wet the coffee grounds. Pour a small amount of water to wet the grounds, and wait for about 30 seconds to allow the coffee to bloom.\n",
      "Context Length: 3434\n",
      "[468.0s] REF : Just pour it slowly and evenly.\n",
      "[468.0s] GEN : \n",
      "Context Length: 3474\n",
      "[470.5s] USER: Okay\n",
      "[470.5s] REF : Pour the water in a circular motion, slowly, so it doesn't overfill.\n",
      "[470.5s] GEN : \n",
      "Context Length: 3530\n",
      "[474.5s] USER: Ok\n",
      "[474.5s] REF : This helps the coffee drip evenly and prevents a mess.\n",
      "[474.5s] GEN : \n",
      "Context Length: 3616\n",
      "[478.5s] USER: How much water should I pour in?\n",
      "[478.5s] REF : Pour all of it, until the water level is about an inch from the top.\n",
      "[478.5s] GEN : \n",
      "Context Length: 3709\n",
      "[482.0s] REF : \n",
      "[482.0s] GEN : Just a small amount, enough to wet all the grounds.\n",
      "Context Length: 3795\n",
      "[487.5s] REF : \n",
      "[487.5s] GEN : Remember to wait for 30 seconds to allow the coffee to bloom.\n",
      "Context Length: 3923\n",
      "IPS envoked - Generated summary: The time elapsed since the start of the task is 453.5 seconds. The user wants to make pour-over coffee, and so far, they have boiled water, measured out 12 ounces of water, assembled the filter cone, prepared the paper filter, measured out 25 grams of coffee beans, ground the coffee beans, and are currently at the step of wetting the coffee grounds, with the assistant guiding them through each step and answering their questions about the process, including clarifying the use of the scale, folding the filter, and grinding the beans.\n",
      "[519.0s] REF : You're doing great! The coffee is starting to drip through.\n",
      "[519.0s] GEN : \n",
      "Context Length: 1058\n",
      "[523.0s] USER: Ok\n",
      "[523.0s] REF : Just be patient and let it finish dripping.\n",
      "[523.0s] GEN : Great! Now, let the coffee drain completely.\n",
      "Context Length: 1158\n",
      "[603.0s] REF : Now, let's move on to the final step. The coffee should be fully dripped by now.\n",
      "[603.0s] GEN : \n",
      "Context Length: 2758\n",
      "[635.0s] USER: I think the bottom is already full because it originally had some water in it. Is it fine?\n",
      "[635.0s] REF : Yes, that's okay. The extra water won't affect the flavor.\n",
      "[635.0s] GEN : That's okay! If it's already full, it's fine to leave it as is.\n",
      "Context Length: 3446\n",
      "[639.0s] REF : Once the water finishes draining, you can discard the paper filter.\n",
      "[639.0s] GEN : \n",
      "Context Length: 3526\n",
      "[640.0s] REF : \n",
      "[640.0s] GEN : Just make sure the coffee is draining into the mug.\n",
      "Context Length: 3561\n",
      "[642.5s] USER: Oh, this is a bit hot. It's already full.\n",
      "[642.5s] REF : Be careful, yes. It's hot. But you're almost done!\n",
      "[642.5s] GEN : Be careful, then! Handle the mug with care.\n",
      "Context Length: 3644\n",
      "[648.0s] REF : Once the water finishes draining, you can discard the paper filter.\n",
      "[648.0s] GEN : \n",
      "Context Length: 3754\n",
      "[653.0s] REF : \n",
      "[653.0s] GEN : Okay, that's done! You've successfully made pour-over coffee.\n",
      "Context Length: 3872\n",
      "[654.0s] REF : \n",
      "[654.0s] GEN : Now, let's wait for the coffee to drain completely. This might take a few minutes.\n",
      "Context Length: 3915\n",
      "[655.0s] REF : \n",
      "[655.0s] GEN : When the coffee drains completely, you can discard the paper filter and the coffee grounds.\n",
      "Context Length: 3956\n",
      "[655.5s] USER: Ok\n",
      "[655.5s] REF : \n",
      "[655.5s] GEN : \n",
      "Context Length: 3972\n",
      "IPS envoked - Generated summary: The time elapsed since the start of the task is 612.9 seconds. The user's task goal is to make pour-over coffee, and so far, they have boiled water, measured out 12 ounces of water, assembled the filter cone, prepared the paper filter, measured out 25 grams of coffee beans, ground the beans, checked the water temperature, and wet the coffee grounds; other topics mentioned include clarifying the use of the scale, folding the filter, and handling hot objects; the current state is that the coffee is draining into the mug, and the user is waiting for it to drain completely before discarding the filter and grounds.\n",
      "[660.5s] USER: Um, can...\n",
      "[660.5s] REF : Yes, you can discard the filter now. Just the paper filter, not the metal cone.\n",
      "[660.5s] GEN : You can just let it drain completely.\n",
      "Context Length: 617\n",
      "[663.0s] REF : Just throw it away in the trash.\n",
      "[663.0s] GEN : \n",
      "Context Length: 667\n",
      "[671.5s] USER: Just the paper, um, discard filter in the trash.\n",
      "[671.5s] REF : That's right! You're all done.\n",
      "[671.5s] GEN : That's right! Just discard the paper filter in the trash.\n",
      "Context Length: 871\n",
      "[684.5s] USER: Ok\n",
      "[684.5s] REF : \n",
      "[684.5s] GEN : Great job! You're almost done.\n",
      "Context Length: 1149\n",
      "[687.5s] REF : You should be all set! Your pour-over coffee is ready.\n",
      "[687.5s] GEN : \n",
      "Context Length: 1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "for i in [3]:\n",
    "    video = dataset[i]\n",
    "    streams = runner.processor.processed_conv_data_to_stream(video)\n",
    "    outputs = runner.run_inference_on_video(\n",
    "        video,\n",
    "        streams=streams,\n",
    "        use_gt_context=False,\n",
    "        verbose=True,\n",
    "        video_output_dir=\"video\", # the output will be saved to `video/3.mp4`\n",
    "        max_time=60, # restrict the inference time to 60s; remove to run until the end of the video, and see how IPS work for context management\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
